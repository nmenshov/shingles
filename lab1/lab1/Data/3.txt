Wongun Choi, Caroline Pantofaru, Silvio Savarese, "A General Framework for Tracking Multiple People from a Moving Camera", PAMI (under revision, accepted with minor revision).
Wongun Choi and Silvio Savarese, "Multiple Target Tracking in World Coordinate with Single, Minimally Calibrated Camera", ECCV 2010 (pdf).
Wongun Choi, Caroline Pantofaru, Silvio Savarese, "Detecting and Tracking People using an RGB-D Camera via Multiple Detector Fusion" CORP (in conjunction with ICCV) 2011 (pdf).
In this project, we aim to solve a challenging problem of multi-target tracking under unknown camera motion. To meet the most general condition of tracking applications, we did not rely on the use of stereo-camera and SfM algorithm. To cope with the unknown camera motion as well as frequent occlusion between targets, the targets were tracked in the 3D coordinate and the camera's parameters are estimated in a joint fashion. Specifically, our goals are to: i) solve the multi-object tracking problem by using a single uncalibrated moving camera; ii) handle complex scenes where multiple pedestrians are moving at the same time and occluding each other; iii) estimate the 2D/3D temporal trajectories within the camera reference system.

caused by the high dimensionality of the representation, we incorporate MCMC particle filtering algorithm which finds the best explanation in sequential fashion. Notice that, unlike previous methods using MCMC, our method is the first that uses MCMC for efficiently solving the joint camera estimation and multi-target problem.

The second key contribution is that we obtain robust and stable tracking results (i.e. uniquely associate object identities to each track) by incorporating interaction models. Interaction between targets have been largely ignored in the object tracking literature, due to the high complexity in modeling moving targets and the consequential computational complexity. The independent assumption is reasonable when the scene is sparse (only few objects exists in the scene). In a crowded scene, however, the independent motion model often fails to account for the target's deviation from the prediction, e.g. if a collision is expected, targets will change their velocity and direction rapidly so as to avoid a collision. Thus, modeling interactions allows us to disambiguate occlusions between targets and better associate object labels to underlying trajectories. This capability is further enhanced by the fact that our trajectories are estimated in 3D rather than in the image plane. Our interaction models are coherently integrated in the graphical model introduced above.

We validate our theoretical results in a number of experiments using our own dataset (provided below) and the publicly available ETH dataset. Also, a new RGB-D dataset collected using Kinect camera mounted on a robot (will be available soon) is used to evaluate our algotithm. Please see the eccv paper and workshop paper for more details. The poster presented in ECCV is available as well.